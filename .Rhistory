formuleT<-GENRE~.
ModT<-model(formuleT,data=df[train==TRUE,])
####Modele1####
###############
####Récupérations des variables significatives
library(stats)
ind_variables_nonsign=which(summary(ModT)$coefficients[,4]>=0.05)
names(df)[ind_variables_nonsign]
####Mis à jour du modèle en supprimant les variables significatives
formule1<-GENRE~.-PAR_TC-PAR_SC-PAR_SC_V-PAR_ASE1-PAR_ASS_V-PAR_SFMV2-PAR_SFMV3-PAR_SFMV4-PAR_SFMV5-PAR_SFMV6-PAR_SFMV7-PAR_SFMV8-PAR_SFMV9-PAR_SFMV10-
PAR_SFMV11-PAR_SFMV12-PAR_SFMV13-PAR_SFMV14-PAR_SFMV15-PAR_SFMV16-PAR_SFMV17-PAR_SFMV18-PAR_SFMV19-PAR_SFMV20-PAR_SFMV21-PAR_SFMV22-PAR_SFMV23-PAR_SFMV24-
PAR_SFM_MV-PAR_MFCC1-PAR_MFCC2-PAR_MFCC3-PAR_MFCC6-PAR_MFCC7-PAR_MFCC8-PAR_MFCC12-PAR_MFCC14-PAR_MFCC15-PAR_MFCC16-PAR_MFCC17-PAR_MFCC18-PAR_THR_3RMS_TOT-
PAR_THR_1RMS_10FR_MEAN-PAR_THR_1RMS_10FR_VAR-PAR_THR_2RMS_10FR_MEAN-PAR_PEAK_RMS_TOT-PAR_PEAK_RMS10FR_MEAN-PAR_PEAK_RMS10FR_VAR-PAR_1RMS_TCD-PAR_2RMS_TCD-
PAR_3RMS_TCD-PAR_ZCD_10FR_MEAN-PAR_ZCD_10FR_VAR-PAR_1RMS_TCD_10FR_MEAN-PAR_1RMS_TCD_10FR_VAR-PAR_2RMS_TCD_10FR_MEAN-PAR_2RMS_TCD_10FR_VAR-PAR_3RMS_TCD_10FR_MEAN-
PAR_3RMS_TCD_10FR_VAR
Mod1=model(formule1,data=df[train==TRUE,])
####Modele2####
###############
####Récupérations des variables significatives
ind_variables_nonsign=which(summary(ModT)$coefficients[,4]>=0.2)
nom_variables_nonsign=names(df)[ind_variables_nonsign]
####Mis à jour du modèle en supprimant les variables significatives
formule2<-GENRE~.-PAR_SC-PAR_SC_V-PAR_ASE1-PAR_ASS_V-PAR_SFMV2-PAR_SFMV3-PAR_SFMV4-PAR_SFMV5-PAR_SFMV6-PAR_SFMV7-PAR_SFMV8-PAR_SFMV9-PAR_SFMV10-
PAR_SFMV11-PAR_SFMV12-PAR_SFMV13-PAR_SFMV14-PAR_SFMV15-PAR_SFMV16-PAR_SFMV17-PAR_SFMV18-PAR_SFMV19-PAR_SFMV20-PAR_SFMV21-PAR_SFMV22-PAR_SFMV23-PAR_SFMV24-
PAR_SFM_MV-PAR_MFCC1-PAR_MFCC6-PAR_MFCC8-PAR_MFCC15-PAR_MFCC16-PAR_MFCC17-
PAR_THR_1RMS_10FR_MEAN-PAR_THR_2RMS_10FR_MEAN-PAR_PEAK_RMS_TOT-PAR_PEAK_RMS10FR_VAR-PAR_1RMS_TCD-
PAR_ZCD_10FR_MEAN-PAR_ZCD_10FR_VAR-PAR_1RMS_TCD_10FR_MEAN-PAR_2RMS_TCD_10FR_MEAN-PAR_3RMS_TCD_10FR_MEAN-
PAR_3RMS_TCD_10FR_VAR
Mod2=model(formule2,data=df[train==TRUE,])
####ModAIC####
###############
library(MASS)
#ModAIC=stepAIC(ModT,scope=list(upper=GENRE~.,lower=GENRE~1))
################
### Q4
################
library(ROCR)
library(pROC)
####Premier graph
#Echantillon apprentissage
pred=predict(ModT)
ROC_T_train=roc(df$GENRE[train==TRUE],pred)
plot(ROC_T_train, xlab="", col="blue",main="courbes ROC")
#Echantillon test
pred=predict(ModT,newdata=df[train==FALSE,])
ROC_T_test=roc(df$GENRE[train==FALSE],pred)
lines(ROC_T_test, xlab="", col="red",main="courbes ROC")
legend(0.4,0.2,legend=c("Apprentissage","Test"),col=c("blue","red"),lty=1)
#Règle parfaite
#lines(0:length(ROC_T_test)/1:length(ROC_T_test)) à voir comment faire
pred=predict(ModT,newdata=df[train==FALSE,])
ROC_T_test=roc(df$GENRE[train==FALSE],pred)
plot(ROC_T_test, xlab="", col=1,main="Superposition courbes ROC")
pred=predict(Mod1,newdata=df[train==FALSE,])
ROC_1_test=roc(df$GENRE[train==FALSE],pred)
lines(ROC_1_test, xlab="", col=2,main="Superposition courbes ROC")
pred=predict(Mod2,newdata=df[train==FALSE,])
ROC_2_test=roc(df$GENRE[train==FALSE],pred)
lines(ROC_2_test, xlab="", col=3,main="Superposition courbes ROC")
legend(0.6,0.2,legend=c(paste("ModT :",toString(auc(ROC_T_test))),paste("Mod1 :",toString(auc(ROC_1_test))),paste("Mod2 :",toString(auc(ROC_2_test)))), col=c(1:3),lty=1)
################
### Q4
################
################
### Q4
################
predproba = predict(ModT,type="response")         # prédiction en proba
sum(predproba<10^-13)   #  # proba nulle
sum(predproba>1-10^-13) # # proba 1
predproba
sum(predproba<10^-3)   #  # proba nulle
sum(predproba>1-10^-3) # # proba 1
df=read.table("Music_2023.txt",dec='.',header=TRUE,sep=';')
##########################################################################################################################################
##########################################################################################################################################
##########################################################Partie I########################################################################
##########################################################################################################################################
##########################################################################################################################################
################
### Q1
################
####Analyse univarié
summary(df)  #Toutes les variables sauf la dernière sont numériques
str(df)
####Analyse bivariée (à voir)
par(mfrow=c(3,3))
apply(cbind(names(df)),1, function(x)
{boxplot(spam[,x]~df$GENRE,xlab=x, horizontal=TRUE);return()  })
par(mfrow=c(3,3))
apply(cbind(names(df)),1, function(x)
{boxplot(df[,x]~df$GENRE,xlab=x, horizontal=TRUE);return()  })
df$GENRE=as.numeric(factor(df$GENRE))-1
par(mfrow=c(3,3))
apply(cbind(names(df)),1, function(x)
{boxplot(df[,x]~df$GENRE,xlab=x, horizontal=TRUE);return()  })
dev.off()
####Variable très corrélées
C=cor(df[,-172])-diag(1,171)
######Projet final STA203 - Apprentissage supervisé########
###########################################################
# Nom1 = Limes
# Nom2 = Perdrix
rm(list=objects()); graphics.off()
setwd("C:/Users/lucie/OneDrive/Documents/Documents/ENSTA/2A/STA203/PROJETSTA203")
#Package
library(ggplot2)
library(GGally)
library(corrplot)
library(caret)
#Importation des données
df=read.table("Music_2023.txt",dec='.',header=TRUE,sep=';')
##########################################################################################################################################
##########################################################################################################################################
##########################################################Partie I########################################################################
##########################################################################################################################################
##########################################################################################################################################
################
### Q1
################
####Analyse univarié
summary(df)  #Toutes les variables sauf la dernière sont numériques
str(df)
####Analyse bivariée (à voir)
####Proportion de chacun des genres
p_classique=sum(df$GENRE=="Classical")/length(df$GENRE)  #0.53
p_jazz=sum(df$GENRE=="Jazz")/length(df$GENRE)            #0.47
####PAR_SC_V, PAR_ASC_V
summary(df$PAR_SC_V)
mean(df$PAR_SC_V)      #105222.8
summary(df$PAR_ASC_V)
mean(df$PAR_ASC_V)     #0.4251288
#Le passage au log peut-être judicieux pour normaliser les valeurs
df$PAR_SC_V=log(df$PAR_SC_V)
df$PAR_ASC_V=log(df$PAR_ASC_V)
####D'après l'annexe, les paramètres 148 à 167 sont les mêmes que les paramètres 128 à 147 donc on peut les supprimer
df=cbind(df[1:147],df[168:192])
####Variable très corrélées
C=cor(df[,-172])-diag(1,171)
cbind(which(C>0.8)%/%57 +1, which(C>0.8)%%57)
cbind(which(C>0.99)%/%57 +1, which(C>0.99)%%57)
cbind(which(C>0.99)%/%57 +1, which(C>0.99)%/%57)
c(C[106,105],C[109,108],C[212,211],C[215,214],C[480,479],C[492,491])
cbind(which(C>0.99)%/%57 +1, which(C>0.99)%%57)
c(C[106,37],C[109,36],C[212,15],C[215,14],C[480,50],C[492,46])
which(C>0.99)
cbind(which(C>0.99)%/%171 +1, which(C>0.99)%%171)
c(C[36,37],C[71,72],C[160,164])
?cutoff
high_cor_vars <- findCorrelation(C, cutoff = 0.99)
#Suppression des variables
df=df[,-c(37,72,160)]
################
### Q1
################
df$GENRE=as.numeric(factor(df$GENRE))-1
myplot = function(x,Y,xlab=""){
plot(x,Y,xlab=xlab, col=Y+1,pch=Y+1);
boxplot(x~Y,xlab=xlab,horizontal=TRUE)
}
par(mfcol=c(2,1))
myplot(df$PAR_ASE_M,df$GENRE)
myplot(df$PAR_SC_V,df$GENRE)
myplot(log(df$PAR_SC_V),df$GENRE)
myplot(df$PAR_ASC_V,df$GENRE)
myplot(log(df$PAR_ASC_V),df$GENRE)
myplot(df$PAR_ASE_M,df$GENRE)
myplot(df$PAR_ASE_MV,df$GENRE)
myplot(df$PAR_SFM_M,df$GENRE)
myplot(df$PAR_SFM_MV,df$GENRE)
myplot(df$PAR_ASE_M,df$GENRE)
myplot(df$PAR_ASE_MV,df$GENRE)
myplot(df$PAR_SFM_M,df$GENRE)
myplot(df$PAR_SFM_MV,df$GENRE)
error_classif=function(data,modele,seuil=0.5)
{
predproba = predict(modele,type="response")
glm.pred = ifelse(predproba>.5,1,0)
return(1-mean(glm.pred==data$GENRE))
}
##ModT
#Apprentissage
error_classif(df[train==TRUE,],ModT,0.5)
######Projet final STA203 - Apprentissage supervisé########
###########################################################
# Nom1 = Limes
# Nom2 = Perdrix
rm(list=objects()); graphics.off()
setwd("C:/Users/lucie/OneDrive/Documents/Documents/ENSTA/2A/STA203/PROJETSTA203")
#Package
library(ggplot2)
library(GGally)
library(corrplot)
library(caret)
#Importation des données
df=read.table("Music_2023.txt",dec='.',header=TRUE,sep=';')
##########################################################################################################################################
##########################################################################################################################################
##########################################################Partie I########################################################################
##########################################################################################################################################
##########################################################################################################################################
################
### Q1
################
df$GENRE=as.numeric(factor(df$GENRE))-1
####Analyse univarié
summary(df)  #Toutes les variables sauf la dernière sont numériques
str(df)
####Analyse bivariée (à voir)
####Proportion de chacun des genres
p_classique=sum(df$GENRE=="Classical")/length(df$GENRE)  #0.53
p_jazz=sum(df$GENRE=="Jazz")/length(df$GENRE)            #0.47
####PAR_SC_V, PAR_ASC_V
myplot = function(x,Y,xlab=""){
plot(x,Y,xlab=xlab, col=Y+1,pch=Y+1);
boxplot(x~Y,xlab=xlab,horizontal=TRUE)
}
par(mfcol=c(2,1))
summary(df$PAR_SC_V)
mean(df$PAR_SC_V)      #105222.8
myplot(log(df$PAR_SC_V),df$GENRE)
summary(df$PAR_ASC_V)
mean(df$PAR_ASC_V)     #0.4251288
myplot(log(df$PAR_ASC_V),df$GENRE)
#Le passage au log peut-être judicieux pour normaliser les valeurs
df$PAR_SC_V=log(df$PAR_SC_V)
df$PAR_ASC_V=log(df$PAR_ASC_V)
####D'après l'annexe, les paramètres 148 à 167 sont les mêmes que les paramètres 128 à 147 donc on peut les supprimer
df=cbind(df[1:147],df[168:192])
####Variable très corrélées
C=cor(df[,-172])-diag(1,171)
cbind(which(C>0.99)%/%171 +1, which(C>0.99)%%171)
c(C[36,37],C[71,72],C[160,164])
#0.9997459 0.9981005 0.9950279
#Suppression des variables
df=df[,-c(37,72,160)]
####Cas des variables mntionnées
par(mfcol=c(2,1))
myplot(df$PAR_ASE_M,df$GENRE) #Idem
myplot(df$PAR_ASE_MV,df$GENRE) #Pas de relation importante
myplot(df$PAR_SFM_M,df$GENRE)
myplot(df$PAR_SFM_MV,df$GENRE) #Ne semble pas avoir une relation importante avec le genre
####Définition du modèle logistique
model = function(formule,data)
{
return(glm(formule, family=binomial(link="logit"),data=data))
}
#Binomial car on veut expliquer une variable binaire
################
### Q2
################
set.seed(103)
n=nrow(df)
train=sample(c(TRUE,FALSE),n,rep=TRUE,prob=c(2/3,1/3))
################
### Q3
################
####Modele0####
###############
formule0<-GENRE~PAR_TC + PAR_SC + PAR_SC_V + PAR_ASE_M + PAR_ASE_MV + PAR_SFM_M + PAR_SFM_MV
Mod0<-model(formule0,data=df[train==TRUE,])
####ModeleT####
###############
formuleT<-GENRE~.
ModT<-model(formuleT,data=df[train==TRUE,])
####Modele1####
###############
####Récupérations des variables significatives
library(stats)
ind_variables_nonsign=which(summary(ModT)$coefficients[,4]>=0.05)
names(df)[ind_variables_nonsign]
####Mis à jour du modèle en supprimant les variables significatives
formule1<-GENRE~.-PAR_TC-PAR_SC-PAR_SC_V-PAR_ASE1-PAR_ASS_V-PAR_SFMV2-PAR_SFMV3-PAR_SFMV4-PAR_SFMV5-PAR_SFMV6-PAR_SFMV7-PAR_SFMV8-PAR_SFMV9-PAR_SFMV10-
PAR_SFMV11-PAR_SFMV12-PAR_SFMV13-PAR_SFMV14-PAR_SFMV15-PAR_SFMV16-PAR_SFMV17-PAR_SFMV18-PAR_SFMV19-PAR_SFMV20-PAR_SFMV21-PAR_SFMV22-PAR_SFMV23-PAR_SFMV24-
PAR_SFM_MV-PAR_MFCC1-PAR_MFCC2-PAR_MFCC3-PAR_MFCC6-PAR_MFCC7-PAR_MFCC8-PAR_MFCC12-PAR_MFCC14-PAR_MFCC15-PAR_MFCC16-PAR_MFCC17-PAR_MFCC18-PAR_THR_3RMS_TOT-
PAR_THR_1RMS_10FR_MEAN-PAR_THR_1RMS_10FR_VAR-PAR_THR_2RMS_10FR_MEAN-PAR_PEAK_RMS_TOT-PAR_PEAK_RMS10FR_MEAN-PAR_PEAK_RMS10FR_VAR-PAR_1RMS_TCD-PAR_2RMS_TCD-
PAR_3RMS_TCD-PAR_ZCD_10FR_MEAN-PAR_ZCD_10FR_VAR-PAR_1RMS_TCD_10FR_MEAN-PAR_1RMS_TCD_10FR_VAR-PAR_2RMS_TCD_10FR_MEAN-PAR_2RMS_TCD_10FR_VAR-PAR_3RMS_TCD_10FR_MEAN-
PAR_3RMS_TCD_10FR_VAR
Mod1=model(formule1,data=df[train==TRUE,])
####Modele2####
###############
####Récupérations des variables significatives
ind_variables_nonsign=which(summary(ModT)$coefficients[,4]>=0.2)
nom_variables_nonsign=names(df)[ind_variables_nonsign]
####Mis à jour du modèle en supprimant les variables significatives
formule2<-GENRE~.-PAR_SC-PAR_SC_V-PAR_ASE1-PAR_ASS_V-PAR_SFMV2-PAR_SFMV3-PAR_SFMV4-PAR_SFMV5-PAR_SFMV6-PAR_SFMV7-PAR_SFMV8-PAR_SFMV9-PAR_SFMV10-
PAR_SFMV11-PAR_SFMV12-PAR_SFMV13-PAR_SFMV14-PAR_SFMV15-PAR_SFMV16-PAR_SFMV17-PAR_SFMV18-PAR_SFMV19-PAR_SFMV20-PAR_SFMV21-PAR_SFMV22-PAR_SFMV23-PAR_SFMV24-
PAR_SFM_MV-PAR_MFCC1-PAR_MFCC6-PAR_MFCC8-PAR_MFCC15-PAR_MFCC16-PAR_MFCC17-
PAR_THR_1RMS_10FR_MEAN-PAR_THR_2RMS_10FR_MEAN-PAR_PEAK_RMS_TOT-PAR_PEAK_RMS10FR_VAR-PAR_1RMS_TCD-
PAR_ZCD_10FR_MEAN-PAR_ZCD_10FR_VAR-PAR_1RMS_TCD_10FR_MEAN-PAR_2RMS_TCD_10FR_MEAN-PAR_3RMS_TCD_10FR_MEAN-
PAR_3RMS_TCD_10FR_VAR
Mod2=model(formule2,data=df[train==TRUE,])
####ModAIC####
###############
library(MASS)
#ModAIC=stepAIC(ModT,scope=list(upper=GENRE~.,lower=GENRE~1))
################
### Q4
################
library(ROCR)
library(pROC)
####Premier graph
#Echantillon apprentissage
pred=predict(ModT)
ROC_T_train=roc(df$GENRE[train==TRUE],pred)
plot(ROC_T_train, xlab="", col="blue",main="courbes ROC")
#Echantillon test
pred=predict(ModT,newdata=df[train==FALSE,])
ROC_T_test=roc(df$GENRE[train==FALSE],pred)
lines(ROC_T_test, xlab="", col="red",main="courbes ROC")
legend(0.4,0.2,legend=c("Apprentissage","Test"),col=c("blue","red"),lty=1)
#Règle parfaite
#lines(0:length(ROC_T_test)/1:length(ROC_T_test)) à voir comment faire
pred=predict(ModT,newdata=df[train==FALSE,])
ROC_T_test=roc(df$GENRE[train==FALSE],pred)
plot(ROC_T_test, xlab="", col=1,main="Superposition courbes ROC")
pred=predict(Mod1,newdata=df[train==FALSE,])
ROC_1_test=roc(df$GENRE[train==FALSE],pred)
lines(ROC_1_test, xlab="", col=2,main="Superposition courbes ROC")
pred=predict(Mod2,newdata=df[train==FALSE,])
ROC_2_test=roc(df$GENRE[train==FALSE],pred)
lines(ROC_2_test, xlab="", col=3,main="Superposition courbes ROC")
legend(0.6,0.2,legend=c(paste("ModT :",toString(auc(ROC_T_test))),paste("Mod1 :",toString(auc(ROC_1_test))),paste("Mod2 :",toString(auc(ROC_2_test)))), col=c(1:3),lty=1)
######Projet final STA203 - Apprentissage supervisé########
###########################################################
# Nom1 = Limes
# Nom2 = Perdrix
rm(list=objects()); graphics.off()
setwd("C:/Users/lucie/OneDrive/Documents/Documents/ENSTA/2A/STA203/PROJETSTA203")
#Package
library(ggplot2)
library(GGally)
library(corrplot)
library(caret)
#Importation des données
df=read.table("Music_2023.txt",dec='.',header=TRUE,sep=';')
##########################################################################################################################################
##########################################################################################################################################
##########################################################Partie I########################################################################
##########################################################################################################################################
##########################################################################################################################################
################
### Q1
################
df$GENRE=as.numeric(factor(df$GENRE))-1
####Analyse univarié
summary(df)  #Toutes les variables sauf la dernière sont numériques
str(df)
####Analyse bivariée (à voir)
####Proportion de chacun des genres
p_classique=sum(df$GENRE=="Classical")/length(df$GENRE)  #0.53
p_jazz=sum(df$GENRE=="Jazz")/length(df$GENRE)            #0.47
####PAR_SC_V, PAR_ASC_V
myplot = function(x,Y,xlab=""){
plot(x,Y,xlab=xlab, col=Y+1,pch=Y+1);
boxplot(x~Y,xlab=xlab,horizontal=TRUE)
}
par(mfcol=c(2,1))
summary(df$PAR_SC_V)
mean(df$PAR_SC_V)      #105222.8
myplot(log(df$PAR_SC_V),df$GENRE)
summary(df$PAR_ASC_V)
mean(df$PAR_ASC_V)     #0.4251288
myplot(log(df$PAR_ASC_V),df$GENRE)
#Le passage au log peut-être judicieux pour normaliser les valeurs
df$PAR_SC_V=log(df$PAR_SC_V)
df$PAR_ASC_V=log(df$PAR_ASC_V)
####D'après l'annexe, les paramètres 148 à 167 sont les mêmes que les paramètres 128 à 147 donc on peut les supprimer
df=cbind(df[1:147],df[168:192])
####Variable très corrélées
C=cor(df[,-172])-diag(1,171)
cbind(which(C>0.99)%/%171 +1, which(C>0.99)%%171)
c(C[36,37],C[71,72],C[160,164])
#0.9997459 0.9981005 0.9950279
#Suppression des variables
df=df[,-c(37,72,160)]
####Cas des variables mntionnées
par(mfcol=c(2,1))
myplot(df$PAR_ASE_M,df$GENRE) #Idem
myplot(df$PAR_ASE_MV,df$GENRE) #Pas de relation importante
myplot(df$PAR_SFM_M,df$GENRE)
myplot(df$PAR_SFM_MV,df$GENRE) #Ne semble pas avoir une relation importante avec le genre
dev.off()
####Définition du modèle logistique
model = function(formule,data)
{
return(glm(formule, family=binomial(link="logit"),data=data))
}
#Binomial car on veut expliquer une variable binaire
################
### Q2
################
set.seed(103)
n=nrow(df)
train=sample(c(TRUE,FALSE),n,rep=TRUE,prob=c(2/3,1/3))
################
### Q3
################
####Modele0####
###############
formule0<-GENRE~PAR_TC + PAR_SC + PAR_SC_V + PAR_ASE_M + PAR_ASE_MV + PAR_SFM_M + PAR_SFM_MV
Mod0<-model(formule0,data=df[train==TRUE,])
####ModeleT####
###############
formuleT<-GENRE~.
ModT<-model(formuleT,data=df[train==TRUE,])
####Modele1####
###############
####Récupérations des variables significatives
library(stats)
ind_variables_nonsign=which(summary(ModT)$coefficients[,4]>=0.05)
names(df)[ind_variables_nonsign]
####Mis à jour du modèle en supprimant les variables significatives
formule1<-GENRE~.-PAR_TC-PAR_SC-PAR_SC_V-PAR_ASE1-PAR_ASS_V-PAR_SFMV2-PAR_SFMV3-PAR_SFMV4-PAR_SFMV5-PAR_SFMV6-PAR_SFMV7-PAR_SFMV8-PAR_SFMV9-PAR_SFMV10-
PAR_SFMV11-PAR_SFMV12-PAR_SFMV13-PAR_SFMV14-PAR_SFMV15-PAR_SFMV16-PAR_SFMV17-PAR_SFMV18-PAR_SFMV19-PAR_SFMV20-PAR_SFMV21-PAR_SFMV22-PAR_SFMV23-PAR_SFMV24-
PAR_SFM_MV-PAR_MFCC1-PAR_MFCC2-PAR_MFCC3-PAR_MFCC6-PAR_MFCC7-PAR_MFCC8-PAR_MFCC12-PAR_MFCC14-PAR_MFCC15-PAR_MFCC16-PAR_MFCC17-PAR_MFCC18-PAR_THR_3RMS_TOT-
PAR_THR_1RMS_10FR_MEAN-PAR_THR_1RMS_10FR_VAR-PAR_THR_2RMS_10FR_MEAN-PAR_PEAK_RMS_TOT-PAR_PEAK_RMS10FR_MEAN-PAR_PEAK_RMS10FR_VAR-PAR_1RMS_TCD-PAR_2RMS_TCD-
PAR_3RMS_TCD-PAR_ZCD_10FR_MEAN-PAR_ZCD_10FR_VAR-PAR_1RMS_TCD_10FR_MEAN-PAR_1RMS_TCD_10FR_VAR-PAR_2RMS_TCD_10FR_MEAN-PAR_2RMS_TCD_10FR_VAR-PAR_3RMS_TCD_10FR_MEAN-
PAR_3RMS_TCD_10FR_VAR
Mod1=model(formule1,data=df[train==TRUE,])
####Modele2####
###############
####Récupérations des variables significatives
ind_variables_nonsign=which(summary(ModT)$coefficients[,4]>=0.2)
nom_variables_nonsign=names(df)[ind_variables_nonsign]
####Mis à jour du modèle en supprimant les variables significatives
formule2<-GENRE~.-PAR_SC-PAR_SC_V-PAR_ASE1-PAR_ASS_V-PAR_SFMV2-PAR_SFMV3-PAR_SFMV4-PAR_SFMV5-PAR_SFMV6-PAR_SFMV7-PAR_SFMV8-PAR_SFMV9-PAR_SFMV10-
PAR_SFMV11-PAR_SFMV12-PAR_SFMV13-PAR_SFMV14-PAR_SFMV15-PAR_SFMV16-PAR_SFMV17-PAR_SFMV18-PAR_SFMV19-PAR_SFMV20-PAR_SFMV21-PAR_SFMV22-PAR_SFMV23-PAR_SFMV24-
PAR_SFM_MV-PAR_MFCC1-PAR_MFCC6-PAR_MFCC8-PAR_MFCC15-PAR_MFCC16-PAR_MFCC17-
PAR_THR_1RMS_10FR_MEAN-PAR_THR_2RMS_10FR_MEAN-PAR_PEAK_RMS_TOT-PAR_PEAK_RMS10FR_VAR-PAR_1RMS_TCD-
PAR_ZCD_10FR_MEAN-PAR_ZCD_10FR_VAR-PAR_1RMS_TCD_10FR_MEAN-PAR_2RMS_TCD_10FR_MEAN-PAR_3RMS_TCD_10FR_MEAN-
PAR_3RMS_TCD_10FR_VAR
Mod2=model(formule2,data=df[train==TRUE,])
####ModAIC####
###############
library(MASS)
#ModAIC=stepAIC(ModT,scope=list(upper=GENRE~.,lower=GENRE~1))
################
### Q4
################
library(ROCR)
library(pROC)
####Premier graph
#Echantillon apprentissage
pred=predict(ModT)
ROC_T_train=roc(df$GENRE[train==TRUE],pred)
plot(ROC_T_train, xlab="", col="blue",main="courbes ROC")
#Echantillon test
pred=predict(ModT,newdata=df[train==FALSE,])
ROC_T_test=roc(df$GENRE[train==FALSE],pred)
lines(ROC_T_test, xlab="", col="red",main="courbes ROC")
legend(0.4,0.2,legend=c("Apprentissage","Test"),col=c("blue","red"),lty=1)
#Règle parfaite
#lines(0:length(ROC_T_test)/1:length(ROC_T_test)) à voir comment faire
pred=predict(ModT,newdata=df[train==FALSE,])
ROC_T_test=roc(df$GENRE[train==FALSE],pred)
plot(ROC_T_test, xlab="", col=1,main="Superposition courbes ROC")
pred=predict(Mod1,newdata=df[train==FALSE,])
ROC_1_test=roc(df$GENRE[train==FALSE],pred)
lines(ROC_1_test, xlab="", col=2,main="Superposition courbes ROC")
pred=predict(Mod2,newdata=df[train==FALSE,])
ROC_2_test=roc(df$GENRE[train==FALSE],pred)
lines(ROC_2_test, xlab="", col=3,main="Superposition courbes ROC")
legend(0.6,0.2,legend=c(paste("ModT :",toString(auc(ROC_T_test))),paste("Mod1 :",toString(auc(ROC_1_test))),paste("Mod2 :",toString(auc(ROC_2_test)))), col=c(1:3),lty=1)
################
### Q4
################
error_classif=function(data,modele,seuil=0.5)
{
predproba = predict(modele,type="response")
glm.pred = ifelse(predproba>.5,1,0)
return(1-mean(glm.pred==data$GENRE))
}
##ModT
#Apprentissage
error_classif(df[train==TRUE,],ModT,0.5)
#Test
error_classif(df[train==FALSE,],ModT,0.5)
error_classif=function(data,modele,seuil=0.5,newdata)
{
predproba = predict(modele,type="response",newdata=newdata)
glm.pred = ifelse(predproba>.5,1,0)
return(1-mean(glm.pred==data$GENRE))
}
##ModT
#Apprentissage
error_classif(df[train==TRUE,],ModT,0.5,df$GENRE[train==TRUE]) #0.06849315
##ModT
#Apprentissage
error_classif(df[train==TRUE,],ModT,0.5,df[train==TRUE,]) #0.06849315
error_classif=function(data,modele,seuil=0.5)
{
predproba = predict(modele,type="response",newdata=data)
glm.pred = ifelse(predproba>.5,1,0)
return(1-mean(glm.pred==data$GENRE))
}
##ModT
#Apprentissage
error_classif(df[train==TRUE,],ModT,0.5) #0.06849315
#Test
error_classif(df[train==FALSE,],ModT,0.5)
##Mod1
#Apprentissage
error_classif(df[train==TRUE,],Mod1,0.5) #0.06849315
#Test
error_classif(df[train==FALSE,],Mod1,0.5) #0.09154437
##Mod2
#Apprentissage
error_classif(df[train==TRUE,],Mod2,0.5) #0.913242
#Test
error_classif(df[train==FALSE,],Mod2,0.5) #0.1104123
#Test
error_classif(df[train==FALSE,],Mod2,0.5) #0.1062194
